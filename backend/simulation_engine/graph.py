"""
ğŸ”„ Meseeing å¯†å¿ƒ - LangGraph å¤šè½®åšå¼ˆå·¥ä½œæµ V6.0
=================================================
æ ¸å¿ƒæ”¹å˜ï¼š
1. å®ç°çœŸæ­£çš„å¤šè½®å¾ªç¯ï¼ˆæœ€å¤š 10 è½®ï¼‰
2. ä¸“å®¶å¿…é¡»è¿½é—®è‡³å°‘ 2-3 æ¬¡æ‰èƒ½å¾—å‡ºç»“è®º
3. è®°å½•å®Œæ•´çš„è¯Šæ–­æ¨ç†é“¾
4. è®¡ç®—æ¯è½®çš„ä¿¡æ¯å¢ç›Š
"""

import json
import re
import operator
import os
from typing import TypedDict, Annotated, List, Optional
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from .prompts import expert_prompt, novice_prompt, opening_prompt
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# =======================================================
# ğŸ›¡ï¸ é…ç½® LLM
# =======================================================
api_key = os.getenv("OPENAI_API_KEY")
api_base = os.getenv("OPENAI_API_BASE", "https://open.bigmodel.cn/api/paas/v4/")

if not api_key:
    raise ValueError("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° OPENAI_API_KEYï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚")

llm = ChatOpenAI(
    model="glm-4",
    temperature=0.3,  # ç¨å¾®æé«˜ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶
    openai_api_key=api_key,
    openai_api_base=api_base
)

# =======================================================
# ğŸ”§ å·¥å…·å‡½æ•°
# =======================================================
def parse_json_robust(text: str) -> Optional[dict]:
    """å¥å£®çš„ JSON è§£æå™¨"""
    text = text.strip()
    
    # å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(text)
    except:
        pass
    
    # å°è¯•ä» markdown ä»£ç å—æå–
    if "```" in text:
        pattern = r"```(?:json)?\s*(.*?)\s*```"
        match = re.search(pattern, text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except:
                pass
    
    # å°è¯•æå– JSON å¯¹è±¡
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if match:
        try:
            json_str = match.group(0).replace('\n', ' ')
            return json.loads(json_str)
        except:
            pass
    
    return None


# =======================================================
# ğŸ“Š çŠ¶æ€å®šä¹‰ (å¢å¼ºç‰ˆ)
# =======================================================
class SimulationState(TypedDict):
    """ä»¿çœŸçŠ¶æ€ - åŒ…å«å®Œæ•´çš„è¯Šæ–­è¿½è¸ª"""
    messages: Annotated[List[BaseMessage], operator.add]
    domain: str
    taxonomy_context: str
    secret_mission: dict  # å°ç™½çš„ç§˜å¯†ä»»åŠ¡
    is_concluded: bool
    turn_count: int
    max_turns: int  # æœ€å¤§è½®æ¬¡é™åˆ¶
    
    # ğŸ†• è¯Šæ–­è¿½è¸ªæ•°æ®
    diagnosis_trace: List[dict]  # æ¯è½®çš„è¯Šæ–­æ¨ç†è®°å½•
    key_questions: List[dict]  # å…³é”®è¿½é—®åˆ—è¡¨
    eliminated_categories: List[str]  # å·²æ’é™¤çš„åˆ†ç±»
    confidence_history: List[float]  # ç½®ä¿¡åº¦å˜åŒ–æ›²çº¿
    final_diagnosis: Optional[dict]  # æœ€ç»ˆè¯Šæ–­ç»“æœ


# =======================================================
# ğŸ­ ç”Ÿæˆå¼€åœºç™½èŠ‚ç‚¹
# =======================================================
def generate_opening_node(state: SimulationState) -> dict:
    """ç”Ÿæˆå°ç™½çš„å¼€åœºç™½ï¼ˆç¡®ä¿ä¸æ³„éœ²ç­”æ¡ˆï¼‰"""
    mission = state["secret_mission"]
    
    chain = opening_prompt | llm
    response = chain.invoke({
        "secret_user_intent": mission.get("novice_intent", ""),
        "secret_category": mission.get("category", ""),
        "persona_role": mission.get("persona", "æ™®é€šäºº"),
        "persona_tone": mission.get("tone", "ç„¦è™‘")
    })
    
    opening = response.content.strip()
    # å»æ‰å¯èƒ½çš„å¼•å·
    opening = opening.strip('"\'')
    
    print(f"   ğŸ’¬ å°ç™½å¼€åœº: {opening[:50]}...")
    
    return {
        "messages": [HumanMessage(content=opening)],
        "turn_count": 1
    }


# =======================================================
# ğŸ¤– ä¸“å®¶è¯Šæ–­èŠ‚ç‚¹
# =======================================================
def expert_node(state: SimulationState) -> dict:
    """ä¸“å®¶è¿›è¡Œè¯Šæ–­è¿½é—®"""
    chain = expert_prompt | llm
    
    response = chain.invoke({
        "domain": state["domain"],
        "taxonomy_context": state["taxonomy_context"],
        "messages": state["messages"]
    })
    
    data = parse_json_robust(response.content)
    
    # æå–è¯Šæ–­æ•°æ®
    diagnosis_trace_entry = {}
    reply = ""
    is_done = False
    confidence = 0.0
    
    if data:
        # æå–è¯Šæ–­æ¨ç†
        reasoning = data.get("diagnosis_reasoning", {})
        analysis = data.get("analysis_data", {})
        reply = data.get("reply_to_user", str(data))
        
        diagnosis_trace_entry = {
            "turn": state["turn_count"],
            "hypotheses": reasoning.get("current_hypotheses", []),
            "key_signals": reasoning.get("key_signals", []),
            "question_purpose": reasoning.get("next_question_purpose", ""),
            "eliminated": reasoning.get("eliminated_categories", []),
            "confidence": reasoning.get("confidence", 0.5),
            "diagnosis": analysis.get("diagnosis", ""),
            "matched_service": analysis.get("matched_service", "")
        }
        
        confidence = reasoning.get("confidence", 0.5)
        
        # åˆ¤æ–­æ˜¯å¦ç»“æŸ
        status = analysis.get("status", "active")
        is_done = (status == "concluded" and state["turn_count"] >= 3)  # è‡³å°‘ 3 è½®
        
    else:
        reply = response.content
        diagnosis_trace_entry = {
            "turn": state["turn_count"],
            "raw_response": reply[:200]
        }
    
    print(f"   ğŸ¤– ä¸“å®¶è¿½é—® (T{state['turn_count']}): {reply[:50]}...")
    
    # æ›´æ–°è¿½è¸ªæ•°æ®
    new_trace = state.get("diagnosis_trace", []) + [diagnosis_trace_entry]
    new_confidence = state.get("confidence_history", []) + [confidence]
    new_eliminated = state.get("eliminated_categories", []) + diagnosis_trace_entry.get("eliminated", [])
    
    # å¦‚æœç»“æŸï¼Œè®°å½•æœ€ç»ˆè¯Šæ–­
    final_diagnosis = None
    if is_done and data:
        final_diagnosis = {
            "service": data.get("analysis_data", {}).get("matched_service", ""),
            "diagnosis": data.get("analysis_data", {}).get("diagnosis", ""),
            "confidence": confidence,
            "total_turns": state["turn_count"],
            "key_questions": [t.get("question_purpose", "") for t in new_trace if t.get("question_purpose")]
        }
    
    return {
        "messages": [AIMessage(content=reply)],
        "is_concluded": is_done,
        "diagnosis_trace": new_trace,
        "confidence_history": new_confidence,
        "eliminated_categories": list(set(new_eliminated)),
        "final_diagnosis": final_diagnosis
    }


# =======================================================
# ğŸ‘¤ å°ç™½å›å¤èŠ‚ç‚¹
# =======================================================
def novice_node(state: SimulationState) -> dict:
    """å°ç™½æ ¹æ®ä¸“å®¶è¿½é—®è¿›è¡Œå›å¤"""
    if state["is_concluded"]:
        return {"messages": []}
    
    mission = state["secret_mission"]
    chain = novice_prompt | llm
    
    response = chain.invoke({
        "secret_user_intent": mission.get("novice_intent", ""),
        "secret_category": mission.get("category", ""),
        "persona_role": mission.get("persona", "æ™®é€šäºº"),
        "persona_tone": mission.get("tone", "ç„¦è™‘"),
        "messages": state["messages"]
    })
    
    data = parse_json_robust(response.content)
    
    if data:
        reply = data.get("response", str(data))
        # è®°å½•é€éœ²å’Œéšè—çš„ä¿¡æ¯
        revealed = data.get("revealed_info", [])
        hidden = data.get("hidden_info", [])
        print(f"   ğŸ‘¤ å°ç™½å›å¤: {reply[:50]}... (é€éœ²: {len(revealed)}, éšè—: {len(hidden)})")
    else:
        reply = response.content
        print(f"   ğŸ‘¤ å°ç™½å›å¤: {reply[:50]}...")
    
    return {
        "messages": [HumanMessage(content=reply)],
        "turn_count": state["turn_count"] + 1
    }


# =======================================================
# ğŸ”€ æ¡ä»¶åˆ¤æ–­å‡½æ•°
# =======================================================
def should_continue(state: SimulationState) -> str:
    """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¯¹è¯"""
    # å¦‚æœå·²ç»ç»“æŸ
    if state.get("is_concluded", False):
        print(f"   âœ… è¯Šæ–­å®Œæˆ! æ€»è½®æ¬¡: {state['turn_count']}")
        return "end"
    
    # å¦‚æœè¶…è¿‡æœ€å¤§è½®æ¬¡
    max_turns = state.get("max_turns", 10)
    if state["turn_count"] >= max_turns:
        print(f"   âš ï¸ è¾¾åˆ°æœ€å¤§è½®æ¬¡ ({max_turns})ï¼Œå¼ºåˆ¶ç»“æŸ")
        return "end"
    
    # ç»§ç»­å¯¹è¯
    return "continue"


# =======================================================
# ğŸ”„ ç»„è£…å·¥ä½œæµ (å¤šè½®å¾ªç¯ç‰ˆ)
# =======================================================
workflow = StateGraph(SimulationState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("opening", generate_opening_node)
workflow.add_node("expert", expert_node)
workflow.add_node("novice", novice_node)

# è®¾ç½®å…¥å£ï¼šå…ˆç”Ÿæˆå¼€åœºç™½
workflow.set_entry_point("opening")

# å¼€åœºç™½åè¿›å…¥ä¸“å®¶è¯Šæ–­
workflow.add_edge("opening", "expert")

# ä¸“å®¶è¯Šæ–­åè¿›å…¥å°ç™½å›å¤
workflow.add_edge("expert", "novice")

# å°ç™½å›å¤åï¼Œæ¡ä»¶åˆ¤æ–­æ˜¯å¦ç»§ç»­
workflow.add_conditional_edges(
    "novice",
    should_continue,
    {
        "continue": "expert",  # ç»§ç»­ä¸‹ä¸€è½®è¿½é—®
        "end": END            # ç»“æŸå¯¹è¯
    }
)

# ç¼–è¯‘å·¥ä½œæµ
app = workflow.compile()


# =======================================================
# ğŸ§ª æµ‹è¯•å‡½æ•°
# =======================================================
def run_simulation_test():
    """è¿è¡Œä¸€æ¬¡å®Œæ•´çš„ä»¿çœŸæµ‹è¯•"""
    from .domain_manager import DomainManager
    
    dm = DomainManager("hr")
    mission = dm.generate_secret_mission()
    
    print("=" * 60)
    print("ğŸ­ å¼€å§‹ AI äº’åšä»¿çœŸ")
    print("=" * 60)
    print(f"ğŸ“‹ ç§˜å¯†ä»»åŠ¡: {mission['novice_intent'][:50]}...")
    print(f"ğŸ¯ ç›®æ ‡åˆ†ç±»: {mission['expert_term']}")
    print(f"ğŸ‘¤ è§’è‰²: {mission.get('persona', 'N/A')} ({mission.get('tone', 'N/A')})")
    print("-" * 60)
    
    initial_state = {
        "messages": [],
        "domain": "hr",
        "taxonomy_context": dm.get_expert_context(),
        "secret_mission": mission,
        "is_concluded": False,
        "turn_count": 0,
        "max_turns": 8,
        "diagnosis_trace": [],
        "key_questions": [],
        "eliminated_categories": [],
        "confidence_history": [],
        "final_diagnosis": None
    }
    
    config = {"recursion_limit": 50}
    final_state = app.invoke(initial_state, config=config)
    
    print("-" * 60)
    print("ğŸ“Š ä»¿çœŸç»“æœ")
    print(f"   æ€»è½®æ¬¡: {final_state['turn_count']}")
    print(f"   ç½®ä¿¡åº¦æ›²çº¿: {final_state.get('confidence_history', [])}")
    print(f"   æ’é™¤åˆ†ç±»: {final_state.get('eliminated_categories', [])}")
    
    if final_state.get("final_diagnosis"):
        fd = final_state["final_diagnosis"]
        print(f"   æœ€ç»ˆè¯Šæ–­: {fd.get('service', 'N/A')}")
        print(f"   è¯Šæ–­ç½®ä¿¡åº¦: {fd.get('confidence', 0):.2%}")
    
    return final_state


if __name__ == "__main__":
    run_simulation_test()