import json
import os
import uuid
import random
from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from fastapi.middleware.cors import CORSMiddleware
from pathlib import Path
from langchain_core.messages import HumanMessage, AIMessage

# å°è¯•å¼•å…¥ä»¿çœŸå¼•æ“ï¼Œå¦‚æœå¤±è´¥åˆ™æ‰“å°è­¦å‘Š
try:
    from simulation_engine.domain_manager import DomainManager
    from simulation_engine.graph import app as graph_app, SimulationState
    SIMULATION_AVAILABLE = True
except ImportError as e:
    print(f"Warning: simulation_engine components not found: {e}")
    SIMULATION_AVAILABLE = False

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# ğŸŒŸ ç»å¯¹è·¯å¾„é”šå®šï¼šå½»åº•è§£å†³â€œæ–‡ä»¶æ‰¾ä¸ç€â€çš„é—®é¢˜
BASE_DIR = Path(__file__).resolve().parent
ROOT_DIR = BASE_DIR.parent
ETL_LOG = ROOT_DIR / "etl_factory" / "processing_log.json"
DB_DIR = BASE_DIR / "domain_db"

# ğŸ”§ ä»¿çœŸä¼šè¯çŠ¶æ€å­˜å‚¨ (ç®€åŒ–ç‰ˆï¼šå•ä¼šè¯)
current_simulation = {
    "state": None,
    "step_count": 0,
    "mission": None,
    "domain": "hr"
}

# ==========================================
# ğŸ® é€†å‘å·¥ç¨‹ï¼šæ¥å£å«ç‰‡ (å…¼å®¹æ‰€æœ‰å‰ç«¯è·¯å¾„)
# ==========================================
@app.post("/api/start")           
@app.post("/api/simulation/start") 
async def start_simulation(data: Dict[str, Any] = None):
    global current_simulation
    domain = data.get("domain", "hr") if data else "hr"
    missions = [
        {"intent": "å‘˜å·¥æ€€å­•äº†ï¼Œæˆ‘æƒ³è®©å¥¹è¾èŒã€‚", "term": "å­•æœŸåˆè§„", "cat": "åŠ³åŠ¨å…³ç³»"},
        {"intent": "æŠ€æœ¯ä¸»ç®¡å¸¦èµ°æ ¸å¿ƒä»£ç å»ç«å¯¹å…¬å¸ã€‚", "term": "ç«ä¸šé™åˆ¶ç®¡ç†", "cat": "å‘˜å·¥å…³ç³»"}
    ]
    selected = random.choice(missions)
    mission = {"novice_intent": selected["intent"], "expert_term": selected["term"], "category": selected["cat"]}
    
    # åˆå§‹åŒ–ä»¿çœŸçŠ¶æ€
    taxonomy_context = DomainManager(domain).get_expert_context() if SIMULATION_AVAILABLE else ""
    current_simulation = {
        "state": {
            "messages": [],
            "domain": domain,
            "taxonomy_context": taxonomy_context,
            "secret_mission": mission,
            "is_concluded": False,
            "turn_count": 0
        },
        "step_count": 0,
        "mission": mission,
        "domain": domain
    }
    
    return {
        "status": "started",
        "thread_id": str(uuid.uuid4()),
        "mission": mission,
        "taxonomy": taxonomy_context
    }

# ==========================================
# ğŸš€ ä»¿çœŸå¼•æ“ï¼šé€æ­¥æ‰§è¡Œ (æ ¸å¿ƒæ–°å¢)
# ==========================================
@app.post("/api/next")
@app.post("/api/simulation/next")
async def next_step():
    global current_simulation
    
    if not current_simulation["state"]:
        raise HTTPException(status_code=400, detail="è¯·å…ˆè°ƒç”¨ /api/start å¼€å§‹ä»¿çœŸ")
    
    state = current_simulation["state"]
    step = current_simulation["step_count"]
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»“æŸ
    if state.get("is_concluded", False):
        return {
            "step": -1,
            "role": "system",
            "content": "ğŸ‰ ä»¿çœŸå·²å®Œæˆï¼ä¸“å®¶å·²æˆåŠŸè¯†åˆ«ç”¨æˆ·æ„å›¾ã€‚",
            "raw_state": True
        }
    
    if not SIMULATION_AVAILABLE:
        # æ¨¡æ‹Ÿæ¨¡å¼ï¼šæ—  LangGraph æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
        step += 1
        current_simulation["step_count"] = step
        
        # è®°å½•å¯¹è¯å†å²
        if "dialogue_history" not in current_simulation:
            current_simulation["dialogue_history"] = []
        
        if step == 1:
            msg = {"step": step, "role": "ai", "content": "æ‚¨å¥½ï¼Œè¯·é—®æ‚¨é‡åˆ°äº†ä»€ä¹ˆäººåŠ›èµ„æºæ–¹é¢çš„é—®é¢˜ï¼Ÿæˆ‘å¯ä»¥å¸®æ‚¨åˆ†æã€‚"}
            current_simulation["dialogue_history"].append(msg)
            return {**msg, "raw_state": False}
        elif step == 2:
            intent = current_simulation["mission"]["novice_intent"]
            msg = {"step": step, "role": "human", "content": intent}
            current_simulation["dialogue_history"].append(msg)
            return {**msg, "raw_state": False}
        elif step == 3:
            term = current_simulation["mission"]["expert_term"]
            msg = {"step": step, "role": "ai", "content": f"æ ¹æ®æ‚¨æè¿°çš„æƒ…å†µï¼Œè¿™å±äºã€Œ{term}ã€é¢†åŸŸçš„é—®é¢˜ã€‚æˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†åˆ†æ..."}
            current_simulation["dialogue_history"].append(msg)
            return {**msg, "raw_state": False}
        else:
            state["is_concluded"] = True
            # ğŸ”§ ä¿å­˜åˆ° ETL æ•°æ®åº“
            save_simulation_to_etl(current_simulation)
            return {"step": -1, "role": "system", "content": f"ğŸ‰ ä»¿çœŸå®Œæˆï¼ä¸“å®¶æˆåŠŸè¯†åˆ«ï¼š{current_simulation['mission']['expert_term']}\n\nâœ… å·²è‡ªåŠ¨ä¿å­˜åˆ° ETL æ•°æ®åº“", "raw_state": True}
    
    # çœŸå®æ¨¡å¼ï¼šè°ƒç”¨ LangGraph å¼•æ“
    try:
        # æ‰§è¡Œä¸€æ­¥ä»¿çœŸ
        result = graph_app.invoke(state)
        
        # æ›´æ–°çŠ¶æ€
        current_simulation["state"] = result
        current_simulation["step_count"] += 1
        step = current_simulation["step_count"]
        
        # è®°å½•å¯¹è¯å†å²
        if "dialogue_history" not in current_simulation:
            current_simulation["dialogue_history"] = []
        
        # æå–æœ€æ–°æ¶ˆæ¯
        messages = result.get("messages", [])
        if messages:
            last_msg = messages[-1]
            role = "ai" if isinstance(last_msg, AIMessage) else "human"
            content = last_msg.content
            current_simulation["dialogue_history"].append({"step": step, "role": role, "content": content})
        else:
            role = "system"
            content = "æ— å“åº”"
        
        is_done = result.get("is_concluded", False)
        
        if is_done:
            # ğŸ”§ ä¿å­˜åˆ° ETL æ•°æ®åº“
            save_simulation_to_etl(current_simulation)
            return {
                "step": -1,
                "role": "system", 
                "content": f"ğŸ‰ ä»¿çœŸå®Œæˆï¼ä¸“å®¶æˆåŠŸè¯†åˆ«ç”¨æˆ·æ„å›¾ã€‚\n\nç›®æ ‡æœ¯è¯­: {current_simulation['mission']['expert_term']}\n\nâœ… å·²è‡ªåŠ¨ä¿å­˜åˆ° ETL æ•°æ®åº“",
                "raw_state": True
            }
        
        return {
            "step": step,
            "role": role,
            "content": content,
            "raw_state": False
        }
        
    except Exception as e:
        return {
            "step": step,
            "role": "error",
            "content": f"ä»¿çœŸå¼•æ“é”™è¯¯: {str(e)}",
            "raw_state": False
        }

# ==========================================
# ğŸ’¾ ä¿å­˜ä»¿çœŸç»“æœåˆ° ETL æ•°æ®åº“
# ==========================================
def save_simulation_to_etl(simulation_data: dict):
    """å°†å®Œæˆçš„ä»¿çœŸä¿å­˜åˆ° ETL æ”¶ä»¶ç®±"""
    from datetime import datetime
    
    mission = simulation_data.get("mission", {})
    dialogue = simulation_data.get("dialogue_history", [])
    
    # æ„å»º ETL è®°å½•
    etl_record = {
        "id": f"sim_{uuid.uuid4().hex[:8]}",
        "timestamp": datetime.now().isoformat(),
        "status": "pending",
        "domain": simulation_data.get("domain", "hr"),
        "query": mission.get("novice_intent", ""),
        "ai_prediction": mission.get("expert_term", ""),
        "category": mission.get("category", ""),
        "confidence": 0.95,  # ä»¿çœŸéªŒè¯çš„ç½®ä¿¡åº¦è¾ƒé«˜
        "source": "simulation_workbench",
        "dialogue_path": [
            {"step": d["step"], "role": d["role"], "content": d["content"][:500]}  # é™åˆ¶é•¿åº¦
            for d in dialogue
        ]
    }
    
    # è¯»å–ç°æœ‰æ•°æ®
    try:
        if ETL_LOG.exists():
            with open(ETL_LOG, 'r', encoding='utf-8') as f:
                inbox = json.load(f)
                if not isinstance(inbox, list):
                    inbox = []
        else:
            inbox = []
    except:
        inbox = []
    
    # æ·»åŠ æ–°è®°å½•
    inbox.insert(0, etl_record)  # æ’å…¥åˆ°æœ€å‰é¢
    
    # ä¿å­˜
    try:
        ETL_LOG.parent.mkdir(parents=True, exist_ok=True)
        with open(ETL_LOG, 'w', encoding='utf-8') as f:
            json.dump(inbox, f, ensure_ascii=False, indent=2)
        print(f"âœ… ETL: å·²ä¿å­˜ä»¿çœŸè®°å½• {etl_record['id']}")
    except Exception as e:
        print(f"âŒ ETL ä¿å­˜å¤±è´¥: {e}")

# ==========================================
# ğŸ“¥ ETL åº“ï¼šå…¨å…¼å®¹å…¥åº“ (æ”¯æŒå•é€‰/å…¨é€‰)
# ==========================================
@app.get("/api/knowledge/logs")
@app.get("/api/etl/inbox")
async def get_etl_inbox():
    if not ETL_LOG.exists(): return []
    try:
        with open(ETL_LOG, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data if isinstance(data, list) else []
    except: return []


@app.post("/api/taxonomy/add")    
@app.post("/api/knowledge/ingest")
@app.post("/api/etl/batch_ingest")
async def universal_ingest(request: Request):
    if not ETL_LOG.exists(): 
        return {"status": "error", "message": "ETL log file not found"}
    
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ Request å¯¹è±¡æ­£ç¡®è§£æ JSON body
    try:
        body = await request.json()
    except Exception as e:
        return {"status": "error", "message": f"Invalid JSON: {str(e)}"}
    
    # ç»Ÿä¸€è§£ææ•°æ®æ ¼å¼
    items = []
    if "items" in body: 
        items = body["items"]
    else: 
        items = [{"id": body.get("id"), "domain": body.get("domain", "hr")}]
    
    print(f"ğŸ“¥ ETL å…¥åº“è¯·æ±‚: {len(items)} æ¡è®°å½•")

    with open(ETL_LOG, 'r', encoding='utf-8') as f:
        inbox = json.load(f)

    db_cache = {}
    success_ids = []

    for item in items:
        rid, dom = item.get("id"), item.get("domain", "hr")
        record = next((r for r in inbox if r["id"] == rid), None)
        if not record: 
            print(f"âš ï¸ æœªæ‰¾åˆ°è®°å½•: {rid}")
            continue
        
        if dom not in db_cache:
            p = DB_DIR / f"{dom}.json"
            if p.exists():
                with open(p, 'r', encoding='utf-8') as f: 
                    db_cache[dom] = json.load(f)
            else:
                print(f"âš ï¸ çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {p}")
                continue

        if dom in db_cache:
            ai_pred = record.get("ai_prediction", "")
            matched = False
            
            # ğŸ”§ ä¿®å¤ï¼šåœ¨ taxonomy çš„ services ä¸­æŸ¥æ‰¾åŒ¹é…çš„æœåŠ¡
            for category in db_cache[dom].get("taxonomy", []):
                services = category.get("services", [])
                
                # æ£€æŸ¥ ai_prediction æ˜¯å¦åœ¨æœåŠ¡åˆ—è¡¨ä¸­ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
                for idx, service in enumerate(services):
                    if ai_pred in service or service in ai_pred or ai_pred == service:
                        # æ‰¾åˆ°åŒ¹é…çš„æœåŠ¡ï¼Œæ·»åŠ è¿½è¸ªè®°å½•
                        if "trace_records" not in category:
                            category["trace_records"] = {}
                        if service not in category["trace_records"]:
                            category["trace_records"][service] = []
                        
                        # æ·»åŠ è®°å½•
                        trace_entry = {
                            "id": record.get("id"),
                            "timestamp": record.get("timestamp"),
                            "query": record.get("query", ""),
                            "ai_prediction": ai_pred,
                            "confidence": record.get("confidence", 0),
                            "source": record.get("source", "etl_inbox")
                        }
                        category["trace_records"][service].append(trace_entry)
                        success_ids.append(rid)
                        matched = True
                        print(f"âœ… å…¥åº“æˆåŠŸ: {ai_pred} â†’ {category['name']}/{service}")
                        break
                
                if matched:
                    break
            
            if not matched:
                # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æ·»åŠ åˆ°å¯¹åº”çš„ category
                for category in db_cache[dom].get("taxonomy", []):
                    cat_name = category.get("name", "")
                    record_cat = record.get("category", "")
                    
                    # æ£€æŸ¥ç±»åˆ«æ˜¯å¦åŒ¹é…
                    if record_cat and (record_cat in cat_name or cat_name in record_cat):
                        # åŠ¨æ€æ·»åŠ æ–°æœåŠ¡åˆ° services åˆ—è¡¨
                        if ai_pred not in category.get("services", []):
                            if "services" not in category:
                                category["services"] = []
                            category["services"].append(ai_pred)
                        
                        # æ·»åŠ è¿½è¸ªè®°å½•
                        if "trace_records" not in category:
                            category["trace_records"] = {}
                        if ai_pred not in category["trace_records"]:
                            category["trace_records"][ai_pred] = []
                        
                        trace_entry = {
                            "id": record.get("id"),
                            "timestamp": record.get("timestamp"),
                            "query": record.get("query", ""),
                            "ai_prediction": ai_pred,
                            "confidence": record.get("confidence", 0),
                            "source": record.get("source", "etl_inbox")
                        }
                        category["trace_records"][ai_pred].append(trace_entry)
                        success_ids.append(rid)
                        print(f"âœ… å…¥åº“æˆåŠŸ (æ–°å¢æœåŠ¡): {ai_pred} â†’ {cat_name}")
                        break
    
    # ä¿å­˜æ›´æ–°åçš„çŸ¥è¯†åº“
    for d, content in db_cache.items():
        with open(DB_DIR / f"{d}.json", 'w', encoding='utf-8') as f:
            json.dump(content, f, ensure_ascii=False, indent=2)

    # æˆåŠŸåä»æ”¶ä»¶ç®±ç§»é™¤
    new_inbox = [r for r in inbox if r["id"] not in success_ids]
    with open(ETL_LOG, 'w', encoding='utf-8') as f:
        json.dump(new_inbox, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“Š ETL å…¥åº“å®Œæˆ: æˆåŠŸ {len(success_ids)} æ¡")
    return {"status": "success", "count": len(success_ids)}

@app.get("/api/taxonomy")
async def get_taxonomy(domain: str = "hr"):
    p = DB_DIR / f"{domain}.json"
    if not p.exists(): return {"service_nodes": []}
    with open(p, 'r', encoding='utf-8') as f: return json.load(f)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)