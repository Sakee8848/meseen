import os
import sys
import json
import time
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# ==========================================
# 1. ç¯å¢ƒå‡†å¤‡
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent
load_dotenv(BASE_DIR / ".env")
sys.path.append(str(BASE_DIR))

# å¼•å…¥ä¸“å®¶æç¤ºè¯
from backend.simulation_engine.prompts import expert_prompt
from backend.simulation_engine.domain_manager import DomainManager

api_key = os.getenv("OPENAI_API_KEY")
api_base = os.getenv("OPENAI_API_BASE", "https://open.bigmodel.cn/api/paas/v4/")

if not api_key:
    raise ValueError("âŒ æœªæ‰¾åˆ° API Key")

print("âœ… ETL æ™ºèƒ½è´¨æ£€å¼•æ“å¯åŠ¨...")

# ==========================================
# 2. å®šä¹‰ AI è§’è‰²
# ==========================================
llm = ChatOpenAI(
    model="glm-4",
    temperature=0.01,
    openai_api_key=api_key,
    openai_api_base=api_base
)

extract_prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æŒ–æ˜ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»éç»“æ„åŒ–çš„â€œåŸå§‹å¯¹è¯è®°å½•â€ä¸­ï¼Œæå–å‡ºç”¨æˆ·æ„å›¾å’Œä¸“å®¶æœåŠ¡åˆ†ç±»ã€‚
ã€åŸå§‹æ•°æ®ã€‘
{raw_text}
ã€æå–è¦æ±‚ã€‘
1. åˆ†æç”¨æˆ·çš„æ ¸å¿ƒç—›ç‚¹ï¼Œæ€»ç»“ä¸º "novice_intent"ã€‚
2. æ ¹æ®ç—›ç‚¹ï¼ŒåŒ¹é…æœ€ä¸“ä¸šçš„ HR æœåŠ¡æœ¯è¯­ï¼Œå®šä¹‰ä¸º "expert_term"ã€‚
3. å¿…é¡»è¾“å‡ºçº¯å‡€ JSONã€‚
""")

# ==========================================
# 3. è¾…åŠ©åŠŸèƒ½ï¼šå­˜æ¡£æ—¥å¿— (New!)
# ==========================================
LOG_FILE = Path(__file__).parent / "processing_log.json"

def save_report(record):
    """æŠŠè´¨æ£€ç»“æœå­˜å…¥ JSON æ–‡ä»¶ï¼Œä¾›å‰ç«¯è¯»å–"""
    if not LOG_FILE.exists():
        with open(LOG_FILE, 'w', encoding='utf-8') as f:
            json.dump([], f)
    
    with open(LOG_FILE, 'r+', encoding='utf-8') as f:
        try:
            data = json.load(f)
        except:
            data = []
        
        # åŠ ä¸Šæ—¶é—´æˆ³å’Œå”¯ä¸€ID
        record["id"] = f"etl_{int(time.time())}"
        record["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        data.append(record)
        f.seek(0)
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æŠ¥å‘Šå·²å­˜æ¡£è‡³: {LOG_FILE.name}")

# ==========================================
# 4. æ ¸å¿ƒåŠŸèƒ½ï¼šæ¨¡æ‹Ÿè€ƒ
# ==========================================
def run_mock_exam(novice_intent, ground_truth_term):
    print(f"\nğŸ“ [æ¨¡æ‹Ÿè€ƒ] æ­£åœ¨æµ‹è¯•å½“å‰ Expert Agent çš„èƒ½åŠ›...")
    
    dm = DomainManager("hr")
    taxonomy_context = dm.get_expert_context()
    
    chain = expert_prompt | llm
    response = chain.invoke({
        "domain": "hr",
        "taxonomy_context": taxonomy_context,
        "messages": [{"role": "user", "content": novice_intent}]
    })
    
    ai_answer_raw = response.content
    print(f"   ğŸ¤– Expert Agent å›ç­”: {ai_answer_raw[:40]}...")
    
    judge_prompt = ChatPromptTemplate.from_template("""
    æˆ‘æ˜¯ç³»ç»Ÿåˆ¤å·å‘˜ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªæœåŠ¡åç§°æ˜¯å¦å±äºåŒä¸€ä¸ªæœåŠ¡èŒƒç•´ï¼Ÿ
    æ ‡å‡†ç­”æ¡ˆ: {ground_truth}
    AIå›ç­”: {ai_answer}
    
    å¦‚æœæ„æ€ç›¸è¿‘ä¸”å±äºåŒä¸€é¢†åŸŸï¼Œè¾“å‡º TRUEã€‚å¦‚æœä¸ç›¸å…³æˆ– AI æ˜ç¡®æ‹’ç»ï¼Œè¾“å‡º FALSEã€‚åªè¾“å‡ºå•è¯ã€‚
    """)
    judge_chain = judge_prompt | llm
    verdict = judge_chain.invoke({
        "ground_truth": ground_truth_term,
        "ai_answer": ai_answer_raw
    }).content.strip()

    return verdict == "TRUE", ai_answer_raw

# ==========================================
# 5. ä¸»æµæ°´çº¿
# ==========================================
def process_file(file_path):
    print(f"\nğŸ“‚ è¯»å–: {file_path.name}")
    with open(file_path, "r", encoding="utf-8") as f:
        raw_content = f.read()

    # Step 1: æå–
    print("â›ï¸  æ­£åœ¨æå– Ground Truth...")
    chain = extract_prompt | llm
    try:
        data_str = chain.invoke({"raw_text": raw_content}).content.strip()
        if "```" in data_str:
            import re
            match = re.search(r"\{.*\}", data_str, re.DOTALL)
            if match: data_str = match.group(0)
            
        data = json.loads(data_str)
        novice_intent = data['novice_intent']
        expert_term = data['expert_term']
        print(f"   ğŸ¯ æå–ç»“æœ: {expert_term}")
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {e}")
        return

    # Step 2: è´¨æ£€
    is_pass, ai_answer = run_mock_exam(novice_intent, expert_term)

    status = "PASS" if is_pass else "REJECT"
    print("-" * 40)
    print(f"ğŸ æœ€ç»ˆåˆ¤å®š: {status}")
    print("-" * 40)

    # Step 3: å­˜æ¡£ (New!)
    report = {
        "file_source": file_path.name,
        "novice_intent": novice_intent,
        "ground_truth_term": expert_term,
        "current_ai_response": ai_answer,
        "status": status, # PASS æˆ– REJECT
        "action_required": not is_pass # å¦‚æœæ˜¯ Rejectï¼Œåˆ™éœ€è¦äººå·¥å¤„ç†
    }
    save_report(report)

if __name__ == "__main__":
    target_file = Path(__file__).parent / "raw_materials" / "demo_chat.txt"
    if target_file.exists():
        process_file(target_file)
    else:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {target_file}")