"""
ğŸ¤– Meseeing æ‰¹é‡ AI äº’åšå¼•æ“ V3.0
===================================
æ”¯æŒ Docker ä¸€é”®éƒ¨ç½²ï¼Œå¸¦æš‚åœ/å–æ¶ˆåŠŸèƒ½

API æ§åˆ¶ç«¯ç‚¹ï¼š
  POST /api/batch/start   - å¯åŠ¨æ‰¹é‡ä»»åŠ¡
  POST /api/batch/pause   - æš‚åœå½“å‰ä»»åŠ¡
  POST /api/batch/resume  - æ¢å¤æš‚åœçš„ä»»åŠ¡
  POST /api/batch/cancel  - å–æ¶ˆä»»åŠ¡
  GET  /api/batch/status  - è·å–å½“å‰çŠ¶æ€
"""

import time
import json
import uuid
import asyncio
import threading
from datetime import datetime
from pathlib import Path
from typing import Optional
from enum import Enum

# å…¨å±€çŠ¶æ€ç®¡ç†
class BatchState(Enum):
    IDLE = "idle"
    RUNNING = "running"
    PAUSED = "paused"
    CANCELLED = "cancelled"
    COMPLETED = "completed"

class BatchRunner:
    def __init__(self):
        self.state = BatchState.IDLE
        self.current_task = 0
        self.total_tasks = 0
        self.results = []
        self.errors = []
        self.start_time = None
        self.worker_thread: Optional[threading.Thread] = None
        self._pause_event = threading.Event()
        self._pause_event.set()  # é»˜è®¤ä¸æš‚åœ
        self._cancel_flag = False
        
        # è·¯å¾„é…ç½®
        self.BASE_DIR = Path(__file__).resolve().parent.parent
        self.LOG_FILE = self.BASE_DIR / "etl_factory" / "processing_log.json"
        self.DB_DIR = Path(__file__).resolve().parent / "domain_db"
        
    def reset(self):
        """é‡ç½®çŠ¶æ€"""
        self.state = BatchState.IDLE
        self.current_task = 0
        self.total_tasks = 0
        self.results = []
        self.errors = []
        self.start_time = None
        self._cancel_flag = False
        self._pause_event.set()
        
    def get_status(self) -> dict:
        """è·å–å½“å‰çŠ¶æ€"""
        elapsed = 0
        if self.start_time:
            elapsed = int((datetime.now() - self.start_time).total_seconds())
        
        return {
            "state": self.state.value,
            "current_task": self.current_task,
            "total_tasks": self.total_tasks,
            "progress": f"{self.current_task}/{self.total_tasks}",
            "progress_percent": int(self.current_task / self.total_tasks * 100) if self.total_tasks > 0 else 0,
            "elapsed_seconds": elapsed,
            "success_count": len(self.results),
            "error_count": len(self.errors),
            "recent_results": self.results[-5:] if self.results else [],
            "recent_errors": self.errors[-3:] if self.errors else []
        }
    
    def save_to_inbox(self, record: dict):
        """ä¿å­˜åˆ° ETL æ”¶ä»¶ç®±"""
        if not self.LOG_FILE.exists():
            self.LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
            with open(self.LOG_FILE, 'w', encoding='utf-8') as f:
                json.dump([], f)
        
        with open(self.LOG_FILE, 'r+', encoding='utf-8') as f:
            try:
                data = json.load(f)
            except:
                data = []
            data.insert(0, record)
            f.seek(0)
            json.dump(data, f, ensure_ascii=False, indent=2)
            f.truncate()
    
    def auto_ingest_to_knowledge_graph(self, record: dict, domain: str = "hr"):
        """ğŸ”§ è‡ªåŠ¨å…¥åº“ï¼šç›´æ¥å°†çŸ¥è¯†ç‚¹æ·»åŠ åˆ°çŸ¥è¯†æ˜Ÿå›¾ï¼ˆå¸¦å»é‡æœºåˆ¶ï¼‰"""
        db_path = self.DB_DIR / f"{domain}.json"
        
        if not db_path.exists():
            print(f"   âš ï¸ çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
            return False
        
        try:
            with open(db_path, 'r', encoding='utf-8') as f:
                db = json.load(f)
            
            ai_pred = record.get("ai_prediction", "")
            record_cat = record.get("category", "")
            query = record.get("query", "")
            matched = False
            
            # åœ¨ taxonomy ä¸­æŸ¥æ‰¾åŒ¹é…çš„æœåŠ¡
            for category in db.get("taxonomy", []):
                services = category.get("services", [])
                cat_name = category.get("name", "")
                
                # æ£€æŸ¥ ai_prediction æ˜¯å¦åŒ¹é…ç°æœ‰æœåŠ¡
                for service in services:
                    if ai_pred in service or service in ai_pred or ai_pred == service:
                        # æ‰¾åˆ°åŒ¹é…çš„æœåŠ¡ï¼Œæ·»åŠ è¿½è¸ªè®°å½•
                        if "trace_records" not in category:
                            category["trace_records"] = {}
                        if service not in category["trace_records"]:
                            category["trace_records"][service] = []
                        
                        # ğŸ”§ å»é‡æœºåˆ¶ï¼šæ£€æŸ¥ç›¸åŒ query + ai_prediction æ˜¯å¦å·²å­˜åœ¨
                        existing_records = category["trace_records"][service]
                        is_duplicate = any(
                            r.get("query") == query and r.get("ai_prediction") == ai_pred
                            for r in existing_records
                        )
                        
                        if is_duplicate:
                            print(f"   â­ï¸ è·³è¿‡é‡å¤: {ai_pred} (queryå·²å­˜åœ¨)")
                            return False
                        
                        trace_entry = {
                            "id": record.get("id"),
                            "timestamp": record.get("timestamp"),
                            "query": record.get("query", ""),
                            "ai_prediction": ai_pred,
                            "confidence": record.get("confidence", 0),
                            "source": record.get("source", "batch_ai_battle"),
                            "persona": record.get("persona", ""),
                            "tone": record.get("tone", ""),
                            # ğŸ†• V6.0 æ–°å¢ï¼šä¿å­˜å¯¹è¯è·¯å¾„
                            "dialogue_path": record.get("dialogue_path", []),
                            "total_turns": record.get("total_turns", 0),
                            "diagnosis_correct": record.get("diagnosis_correct", None),
                            "ground_truth": record.get("ground_truth", "")
                        }
                        category["trace_records"][service].append(trace_entry)
                        matched = True
                        print(f"   ğŸ“Š è‡ªåŠ¨å…¥åº“: {ai_pred} â†’ {cat_name}/{service}")
                        break
                
                if matched:
                    break
            
            # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æŒ‰ç±»åˆ«åŒ¹é…å¹¶æ–°å¢æœåŠ¡
            if not matched and record_cat:
                for category in db.get("taxonomy", []):
                    cat_name = category.get("name", "")
                    if record_cat in cat_name or cat_name in record_cat:
                        # æ·»åŠ æ–°æœåŠ¡
                        if "services" not in category:
                            category["services"] = []
                        if ai_pred not in category["services"]:
                            category["services"].append(ai_pred)
                        
                        # æ·»åŠ è¿½è¸ªè®°å½•
                        if "trace_records" not in category:
                            category["trace_records"] = {}
                        if ai_pred not in category["trace_records"]:
                            category["trace_records"][ai_pred] = []
                        
                        trace_entry = {
                            "id": record.get("id"),
                            "timestamp": record.get("timestamp"),
                            "query": record.get("query", ""),
                            "ai_prediction": ai_pred,
                            "confidence": record.get("confidence", 0),
                            "source": record.get("source", "batch_ai_battle"),
                            "persona": record.get("persona", ""),
                            "tone": record.get("tone", ""),
                            # ğŸ†• V6.0 æ–°å¢ï¼šä¿å­˜å¯¹è¯è·¯å¾„
                            "dialogue_path": record.get("dialogue_path", []),
                            "total_turns": record.get("total_turns", 0),
                            "diagnosis_correct": record.get("diagnosis_correct", None),
                            "ground_truth": record.get("ground_truth", "")
                        }
                        category["trace_records"][ai_pred].append(trace_entry)
                        matched = True
                        print(f"   ğŸ“Š è‡ªåŠ¨å…¥åº“ (æ–°å¢æœåŠ¡): {ai_pred} â†’ {cat_name}")
                        break
            
            if matched:
                # ä¿å­˜æ›´æ–°åçš„çŸ¥è¯†åº“
                with open(db_path, 'w', encoding='utf-8') as f:
                    json.dump(db, f, ensure_ascii=False, indent=2)
                return True
            else:
                print(f"   âš ï¸ æ— æ³•åŒ¹é…: {ai_pred} / {record_cat}")
                return False
                
        except Exception as e:
            print(f"   âŒ è‡ªåŠ¨å…¥åº“å¤±è´¥: {e}")
            return False
    
    def run_single_simulation(self, index: int, domain: str = "hr") -> Optional[dict]:
        """
        è¿è¡Œå•ä¸ªä»¿çœŸä»»åŠ¡ V6.0
        
        æ ¸å¿ƒæ”¹è¿›ï¼š
        1. ä½¿ç”¨å¤šè½®åšå¼ˆå·¥ä½œæµ
        2. æå– AI çœŸæ­£çš„è¯Šæ–­ç»“æœï¼ˆè€ŒéæŠ„ç­”æ¡ˆï¼‰
        3. è®°å½•è¯Šæ–­æ¨ç†é“¾å’Œå…³é”®è¿½é—®
        4. éªŒè¯ AI è¯Šæ–­æ˜¯å¦ä¸å°ç™½ç§˜å¯†ä»»åŠ¡åŒ¹é…
        """
        # æ£€æŸ¥æš‚åœ
        self._pause_event.wait()
        
        # æ£€æŸ¥å–æ¶ˆ
        if self._cancel_flag:
            return None
        
        try:
            from simulation_engine.domain_manager import DomainManager
            
            dm = DomainManager(domain)
            secret = dm.generate_secret_mission()
            thread_id = f"batch_{uuid.uuid4().hex[:8]}"
            
            # åˆå§‹åŒ–ç»“æœå˜é‡
            history = []
            ai_diagnosis = None
            diagnosis_confidence = 0.0
            diagnosis_trace = []
            total_turns = 0
            key_questions = []
            diagnosis_correct = False
            
            # å°è¯•ä½¿ç”¨ LangGraph å¤šè½®å·¥ä½œæµ
            try:
                from simulation_engine.graph import app as graph_app
                expert_ctx = dm.get_expert_context()
                
                # ğŸ†• V6.0 æ–°çŠ¶æ€ç»“æ„
                initial_state = {
                    "messages": [],
                    "domain": domain,
                    "taxonomy_context": expert_ctx,
                    "secret_mission": secret,
                    "is_concluded": False,
                    "turn_count": 0,
                    "max_turns": 8,  # æœ€å¤š 8 è½®
                    "diagnosis_trace": [],
                    "key_questions": [],
                    "eliminated_categories": [],
                    "confidence_history": [],
                    "final_diagnosis": None
                }
                
                config = {"recursion_limit": 50}
                final_state = graph_app.invoke(initial_state, config=config)
                
                # ğŸ†• æå–çœŸæ­£çš„ AI è¯Šæ–­ç»“æœ
                if final_state.get("final_diagnosis"):
                    fd = final_state["final_diagnosis"]
                    ai_diagnosis = fd.get("service", "")
                    diagnosis_confidence = fd.get("confidence", 0.5)
                    key_questions = fd.get("key_questions", [])
                
                # æå–è¯Šæ–­è¿½è¸ª
                diagnosis_trace = final_state.get("diagnosis_trace", [])
                total_turns = final_state.get("turn_count", 0)
                
                # ğŸ†• éªŒè¯è¯Šæ–­æ˜¯å¦æ­£ç¡®
                ground_truth = secret['expert_term']
                if ai_diagnosis:
                    # æ¨¡ç³ŠåŒ¹é…ï¼šæ£€æŸ¥ AI è¯Šæ–­æ˜¯å¦åŒ…å«æ­£ç¡®ç­”æ¡ˆ
                    diagnosis_correct = (
                        ground_truth in ai_diagnosis or 
                        ai_diagnosis in ground_truth or
                        ground_truth.split('/')[0] in ai_diagnosis
                    )
                
                # æå–å¯¹è¯å†å²
                msgs = final_state.get("messages", [])
                for i, msg in enumerate(msgs):
                    content = msg.content if hasattr(msg, 'content') else str(msg)
                    role = "ai" if msg.__class__.__name__ == "AIMessage" else "human"
                    history.append({
                        "step": i + 1,
                        "role": role,
                        "content": content[:300]
                    })
                    
            except ImportError as e:
                # ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼ï¼šæ—  LangGraph æ—¶ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„æ¨¡æ‹Ÿå¯¹è¯
                print(f"   ğŸ“ ä½¿ç”¨å¢å¼ºæ¨¡æ‹Ÿæ¨¡å¼... ({e})")
                
                import random
                
                # æå–åœºæ™¯ä¿¡æ¯
                category = secret.get('category', '')
                expert_term = secret.get('expert_term', '')
                novice_intent = secret.get('novice_intent', '')
                persona = secret.get('persona', 'åˆ›ä¸šè€æ¿')
                
                # ğŸ†• æ ¹æ®åœºæ™¯ç±»å‹ç”Ÿæˆå®Œæ•´çš„äº’åŠ¨å¯¹è¯
                # æ¯ä¸ªåœºæ™¯ç±»å‹æœ‰å¤šç»„å¯¹è¯æ¨¡æ¿ï¼Œæ¯ç»„åŒ…å«è¿½é—®å’Œå›ç­”
                # ğŸ†• æ ¹æ®æ„å›¾å…³é”®è¯ç”Ÿæˆæ›´é€šç”¨çš„äº’åŠ¨å¯¹è¯
                keywords = [k for k in ["ä¿é™©", "èµ”å¿", "å·¥ä¼¤", "åŒ»ç–—", "æ‹›è˜", "è¾é€€", "ä¸ªç¨", "ç¤¾ä¿", "åˆåŒ"] if k in intent_base or k in category]
                kw = keywords[0] if keywords else "ä¸šåŠ¡"
                
                dialogue_templates = {
                    "general": [
                        {"q": f"æ‚¨å…·ä½“é‡åˆ°äº†ä»€ä¹ˆæ ·çš„{kw}é—®é¢˜ï¼Ÿ", "a": f"å°±æ˜¯æœ€è¿‘åœ¨å¤„ç†{kw}è¿™å—ï¼Œæ„Ÿè§‰é£é™©æŒºå¤§çš„ã€‚"},
                        {"q": "ç›®å‰æœ‰å¤šå°‘äººå—åˆ°å½±å“ï¼Ÿ", "a": "å¤§æ¦‚åå‡ ä¸ªå§ï¼Œæ¯”ä¾‹ä¸ç®—å°ã€‚"},
                        {"q": "ä¹‹å‰æœ‰ç±»ä¼¼çš„æ–¹æ¡ˆå—ï¼Ÿ", "a": "æœ‰æ˜¯æœ‰ï¼Œä½†æ„Ÿè§‰ä¸å¤ªåˆè§„ï¼Œæƒ³æ‰¾ä¸“å®¶æŠŠæŠŠå…³ã€‚"}
                    ]
                }
                
                templates = dialogue_templates["general"]
                
                # æ„å»ºè‡ªç„¶çš„å¯¹è¯æµç¨‹
                history = [
                    {
                        "step": 1, 
                        "role": "human", 
                        "content": f"ä½ å¥½ï¼Œ{novice_intent}"
                    },
                    {
                        "step": 2, 
                        "role": "ai", 
                        "content": f"æ‚¨å¥½ï¼æˆ‘æ˜¯ä¸“å®¶ã€‚{templates[0]['q']}"
                    },
                    {
                        "step": 3, 
                        "role": "human", 
                        "content": templates[0]['a']
                    },
                    {
                        "step": 4, 
                        "role": "ai", 
                        "content": f"æ˜ç™½äº†ã€‚é‚£ä¹ˆ{templates[1]['q']}"
                    },
                    {
                        "step": 5, 
                        "role": "human", 
                        "content": templates[1]['a']
                    },
                    {
                        "step": 6, 
                        "role": "ai", 
                        "content": f"æ ¹æ®æ‚¨çš„æè¿°ï¼Œè¿™éå¸¸ç¬¦åˆã€Œ{expert_term}ã€çš„æœåŠ¡èŒƒç•´ã€‚å»ºè®®å°½å¿«å®‰æ’ä¸“ä¸šè¯„ä¼°ã€‚"
                    }
                ]
                
                total_turns = 6
                ai_diagnosis = expert_term
                diagnosis_confidence = 0.85
                diagnosis_correct = True
            
            # ğŸ†• æ„é€ å¢å¼ºç‰ˆè®°å½•
            record = {
                "id": thread_id,
                "timestamp": datetime.now().isoformat(),
                "status": "pending",
                "domain": domain,
                
                # åŸå§‹æ•°æ®
                "query": secret['novice_intent'],
                "ground_truth": secret['expert_term'],  # ğŸ†• çœŸå®ç­”æ¡ˆ
                "category": secret.get('category', ''),
                "persona": secret.get('persona', ''),
                "tone": secret.get('tone', ''),
                
                # ğŸ†• AI è¯Šæ–­ç»“æœ
                "ai_prediction": ai_diagnosis or secret['expert_term'],
                "confidence": diagnosis_confidence,
                "diagnosis_correct": diagnosis_correct,
                
                # ğŸ†• è¯Šæ–­è¿‡ç¨‹
                "dialogue_path": history,
                "total_turns": total_turns,
                "key_questions": key_questions,
                "diagnosis_trace": diagnosis_trace[:3],  # åªä¿å­˜å‰ 3 è½®è¿½è¸ª
                
                "source": "batch_ai_battle_v6"
            }
            
            # ğŸ”§ è‡ªåŠ¨å…¥åº“æ¨¡å¼ï¼šç›´æ¥å…¥åº“åˆ°çŸ¥è¯†æ˜Ÿå›¾
            ingested = self.auto_ingest_to_knowledge_graph(record, domain)
            
            # åŒæ—¶ä¿å­˜ä¸€ä»½åˆ°æ”¶ä»¶ç®±
            self.save_to_inbox(record)
            
            # è¿”å›ç»“æœ
            status_icon = "âœ…" if diagnosis_correct else "âš ï¸"
            return {
                "id": thread_id,
                "query": secret['novice_intent'][:50] + "..." if len(secret['novice_intent']) > 50 else secret['novice_intent'],
                "prediction": ai_diagnosis or secret['expert_term'],
                "ground_truth": secret['expert_term'],
                "correct": diagnosis_correct,
                "turns": total_turns,
                "confidence": diagnosis_confidence,
                "ingested": ingested,
                "success": True
            }
            
        except Exception as e:
            import traceback
            print(f"   âŒ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return {
                "id": f"error_{index}",
                "error": str(e),
                "success": False
            }
    
    def _generate_ambiguous_opening(self, secret: dict) -> str:
        """ç”Ÿæˆæ¨¡ç³Šçš„å¼€åœºç™½ï¼ˆä¸æ³„éœ²ç­”æ¡ˆï¼‰"""
        import random
        
        templates = [
            "ä¸“å®¶ä½ å¥½ï¼Œæˆ‘è¿™è¾¹æœ‰ä¸ªäº‹æƒ…æƒ³é—®é—®ä½ ",
            "å”‰ï¼Œæœ€è¿‘çœŸæ˜¯å¤´ç–¼ï¼Œæœ‰ä¸ªå‘˜å·¥çš„é—®é¢˜ä¸çŸ¥é“æ€ä¹ˆå¤„ç†",
            "æˆ‘æ˜¯{persona}ï¼Œæœ€è¿‘å…¬å¸æœ‰ç‚¹äº‹å„¿æƒ³å’¨è¯¢ä¸€ä¸‹",
            "ä½ å¥½ï¼Œæˆ‘è¿™è¾¹é‡åˆ°ä¸€ä¸ªäº‹æƒ…ï¼Œä¸çŸ¥é“è¯¥æ€ä¹ˆå¼„",
            "ä¸“å®¶ï¼Œæˆ‘æƒ³é—®é—®ä½ ï¼Œæœ‰ä¸ªå‘˜å·¥çš„é—®é¢˜æ€ä¹ˆå¤„ç†å¥½"
        ]
        
        template = random.choice(templates)
        return template.format(persona=secret.get('persona', 'è€æ¿'))
    
    def _worker(self, batch_size: int, domain: str):
        """åå°å·¥ä½œçº¿ç¨‹"""
        self.state = BatchState.RUNNING
        self.total_tasks = batch_size
        self.start_time = datetime.now()
        
        for i in range(batch_size):
            # æ£€æŸ¥å–æ¶ˆ
            if self._cancel_flag:
                self.state = BatchState.CANCELLED
                print(f"ğŸ›‘ æ‰¹é‡ä»»åŠ¡å·²å–æ¶ˆ ({i}/{batch_size})")
                return
            
            # æ£€æŸ¥æš‚åœ
            if not self._pause_event.is_set():
                self.state = BatchState.PAUSED
                print(f"â¸ï¸ æ‰¹é‡ä»»åŠ¡å·²æš‚åœ ({i}/{batch_size})")
            
            self._pause_event.wait()
            
            if self._cancel_flag:
                self.state = BatchState.CANCELLED
                return
            
            self.state = BatchState.RUNNING
            self.current_task = i + 1
            
            print(f"âš¡ï¸ [{i+1}/{batch_size}] æ­£åœ¨è¿è¡Œä»¿çœŸ...")
            result = self.run_single_simulation(i, domain)
            
            if result:
                if result.get("success"):
                    self.results.append(result)
                    print(f"   âœ… æˆåŠŸ: {result.get('prediction', 'N/A')}")
                else:
                    self.errors.append(result)
                    print(f"   âŒ å¤±è´¥: {result.get('error', 'Unknown')}")
            
            # é—´éš”å»¶è¿Ÿ
            time.sleep(1)
        
        self.state = BatchState.COMPLETED
        print(f"ğŸ‰ æ‰¹é‡ä»»åŠ¡å®Œæˆ! æˆåŠŸ: {len(self.results)}, å¤±è´¥: {len(self.errors)}")
    
    def start(self, batch_size: int = 5, domain: str = "hr") -> dict:
        """å¯åŠ¨æ‰¹é‡ä»»åŠ¡"""
        if self.state == BatchState.RUNNING:
            return {"status": "error", "message": "ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­"}
        
        self.reset()
        self._cancel_flag = False
        self._pause_event.set()
        
        self.worker_thread = threading.Thread(
            target=self._worker,
            args=(batch_size, domain),
            daemon=True
        )
        self.worker_thread.start()
        
        return {"status": "started", "batch_size": batch_size, "domain": domain}
    
    def pause(self) -> dict:
        """æš‚åœä»»åŠ¡"""
        if self.state != BatchState.RUNNING:
            return {"status": "error", "message": "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"}
        
        self._pause_event.clear()
        return {"status": "paused", "current_task": self.current_task}
    
    def resume(self) -> dict:
        """æ¢å¤ä»»åŠ¡"""
        if self.state != BatchState.PAUSED:
            return {"status": "error", "message": "æ²¡æœ‰æš‚åœçš„ä»»åŠ¡"}
        
        self._pause_event.set()
        return {"status": "resumed", "current_task": self.current_task}
    
    def cancel(self) -> dict:
        """å–æ¶ˆä»»åŠ¡"""
        if self.state not in [BatchState.RUNNING, BatchState.PAUSED]:
            return {"status": "error", "message": "æ²¡æœ‰å¯å–æ¶ˆçš„ä»»åŠ¡"}
        
        self._cancel_flag = True
        self._pause_event.set()  # è§£é™¤æš‚åœä»¥ä¾¿çº¿ç¨‹å¯ä»¥é€€å‡º
        return {"status": "cancelled", "completed_tasks": self.current_task}


# å…¨å±€å•ä¾‹
batch_runner = BatchRunner()


# ==========================================
# å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œå¯åŠ¨ç®€å•çš„ CLI æ¨¡å¼
# ==========================================
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Meseeing æ‰¹é‡ AI äº’åšå¼•æ“")
    parser.add_argument("--size", type=int, default=5, help="æ‰¹é‡ä»»åŠ¡æ•°é‡")
    parser.add_argument("--domain", type=str, default="hr", help="é¢†åŸŸ")
    args = parser.parse_args()
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ¤– Meseeing æ‰¹é‡ AI äº’åšå¼•æ“ V3.0                     â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  æ‰¹é‡æ•°: {args.size}                                           â•‘
â•‘  é¢†åŸŸ: {args.domain}                                             â•‘
â•‘  æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    result = batch_runner.start(args.size, args.domain)
    print(f"å¯åŠ¨ç»“æœ: {result}")
    
    # ç­‰å¾…å®Œæˆ
    while batch_runner.state in [BatchState.RUNNING, BatchState.PAUSED]:
        time.sleep(2)
        status = batch_runner.get_status()
        print(f"è¿›åº¦: {status['progress']} ({status['progress_percent']}%)")
    
    print(f"\næœ€ç»ˆç»“æœ: {batch_runner.get_status()}")
