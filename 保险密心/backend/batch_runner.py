"""
ğŸ¤– ä¿é™©å¯†å¿ƒ - æ‰¹é‡ AI äº’åšè¿è¡Œå™¨
=================================
è‡ªåŠ¨åŒ–æ‰¹é‡ç”Ÿæˆä¿é™©è¯Šæ–­å¯¹è¯æ ·æœ¬
"""

import json
import asyncio
import uuid
from datetime import datetime
from pathlib import Path
from typing import Optional
from concurrent.futures import ThreadPoolExecutor

# è·¯å¾„é”šå®š
ROOT_DIR = Path(__file__).resolve().parent
ETL_DIR = ROOT_DIR.parent / "etl_factory"
INBOX_PATH = ETL_DIR / "processing_log.json"


class InsuranceBatchRunner:
    """ä¿é™©é¢†åŸŸæ‰¹é‡ä»¿çœŸè¿è¡Œå™¨"""
    
    _instance = None
    _running = False
    _paused = False
    _cancelled = False
    _progress = {"completed": 0, "total": 0, "current": None}
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def start(self, count: int = 10):
        """å¯åŠ¨æ‰¹é‡ä»»åŠ¡"""
        if self._running:
            return {"status": "already_running"}
        
        self._running = True
        self._cancelled = False
        self._paused = False
        self._progress = {"completed": 0, "total": count, "current": None}
        
        # åœ¨åå°çº¿ç¨‹è¿è¡Œ
        executor = ThreadPoolExecutor(max_workers=1)
        executor.submit(self._run_batch, count)
        
        return {"status": "started", "total": count}
    
    def _run_batch(self, count: int):
        """æ‰§è¡Œæ‰¹é‡ä»¿çœŸ"""
        try:
            import os
            from dotenv import load_dotenv
            from simulation_engine.domain_manager import DomainManager
            from simulation_engine.prompts import expert_prompt, novice_prompt, opening_prompt
            from langchain_openai import ChatOpenAI
            from langchain_core.messages import HumanMessage
            
            load_dotenv()
            
            dm = DomainManager("insurance")
            dm.reset_used_scenarios()
            
            # æ™ºè°± API é…ç½®
            api_key = os.getenv("OPENAI_API_KEY")
            api_base = os.getenv("OPENAI_API_BASE", "https://open.bigmodel.cn/api/paas/v4/")
            llm = ChatOpenAI(
                model="glm-4",
                temperature=0.7,
                max_tokens=2000,
                openai_api_key=api_key,
                openai_api_base=api_base
            )
            
            for i in range(count):
                if self._cancelled:
                    break
                
                while self._paused:
                    import time
                    time.sleep(0.5)
                
                # ç”Ÿæˆä»»åŠ¡
                mission = dm.generate_secret_mission()
                self._progress["current"] = {
                    "index": i + 1,
                    "category": mission.get("category_short", mission["category"]),
                    "persona": mission.get("persona", "ä¼ä¸šç®¡ç†è€…")
                }
                
                # æ‰§è¡Œä»¿çœŸ
                result = self._run_single_simulation(llm, dm, mission)
                
                if result:
                    self._save_result(result, mission)
                
                self._progress["completed"] = i + 1
                
        except Exception as e:
            print(f"âŒ æ‰¹é‡è¿è¡Œé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        
        finally:
            self._running = False
            self._progress["current"] = None
    
    def _run_single_simulation(self, llm, dm, mission) -> Optional[dict]:
        """è¿è¡Œå•æ¬¡ä»¿çœŸ"""
        try:
            from simulation_engine.prompts import expert_prompt, novice_prompt, opening_prompt
            from langchain_core.messages import HumanMessage
            
            messages = []
            taxonomy_context = dm.get_expert_context()
            
            # ç”Ÿæˆå¼€åœºç™½
            prompt = opening_prompt.format(
                secret_user_intent=mission["novice_intent"],
                secret_category=mission["category"],
                persona_role=mission.get("persona", "ä¼ä¸šç®¡ç†è€…"),
                persona_tone=mission.get("tone", "è¿·èŒ«")
            )
            
            response = llm.invoke([HumanMessage(content=prompt)])
            opening = response.content.strip()
            
            messages.append({
                "step": 1,
                "role": "human",
                "content": f"æˆ‘æ˜¯{mission.get('persona', 'ä¼ä¸šç®¡ç†è€…')}ï¼Œ{opening}"
            })
            
            # å¤šè½®å¯¹è¯ (æœ€å¤š6è½®)
            final_result = None
            for turn in range(6):
                # é¡¾é—®å“åº”
                messages_text = "\n".join([
                    f"{'å®¢æˆ·' if m['role'] == 'human' else 'é¡¾é—®'}: {m['content']}"
                    for m in messages
                ])
                
                prompt = expert_prompt.format(
                    taxonomy_context=taxonomy_context,
                    messages=messages_text
                )
                
                response = llm.invoke([HumanMessage(content=prompt)])
                
                try:
                    content = response.content.strip()
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0]
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0]
                    expert_data = json.loads(content)
                except:
                    expert_data = {
                        "diagnosis_reasoning": {"confidence": 0.5},
                        "analysis_data": {"status": "active", "matched_service": "å¾…è¯Šæ–­"},
                        "reply_to_user": "è¯·è¯¦ç»†è¯´è¯´ä¼ä¸šæƒ…å†µ"
                    }
                
                messages.append({
                    "step": len(messages) + 1,
                    "role": "ai",
                    "content": expert_data.get("reply_to_user", "è¯·è¯¦ç»†è¯´è¯´")
                })
                
                status = expert_data.get("analysis_data", {}).get("status", "active")
                confidence = expert_data.get("diagnosis_reasoning", {}).get("confidence", 0)
                
                if status == "concluded" or turn >= 5:
                    final_result = {
                        "ai_prediction": expert_data.get("analysis_data", {}).get("matched_service", "æœªè¯Šæ–­"),
                        "confidence": confidence,
                        "total_turns": len(messages)
                    }
                    break
                
                # å®¢æˆ·å“åº”
                messages_text = "\n".join([
                    f"{'å®¢æˆ·' if m['role'] == 'human' else 'é¡¾é—®'}: {m['content']}"
                    for m in messages
                ])
                
                prompt = novice_prompt.format(
                    secret_user_intent=mission["novice_intent"],
                    secret_category=mission["category"],
                    persona_role=mission.get("persona", "ä¼ä¸šç®¡ç†è€…"),
                    persona_tone=mission.get("tone", "è¿·èŒ«"),
                    messages=messages_text
                )
                
                response = llm.invoke([HumanMessage(content=prompt)])
                
                try:
                    content = response.content.strip()
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0]
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0]
                    novice_data = json.loads(content)
                except:
                    novice_data = {"response": "æ˜¯çš„ï¼Œæƒ…å†µå°±æ˜¯è¿™æ ·"}
                
                messages.append({
                    "step": len(messages) + 1,
                    "role": "human",
                    "content": novice_data.get("response", "æ˜¯çš„")
                })
            
            return {
                "messages": messages,
                "final_result": final_result or {"ai_prediction": "æœªå®Œæˆ", "confidence": 0, "total_turns": len(messages)}
            }
            
        except Exception as e:
            print(f"âŒ å•æ¬¡ä»¿çœŸå¤±è´¥: {e}")
            return None
    
    def _save_result(self, result: dict, mission: dict):
        """ä¿å­˜ç»“æœåˆ° ETL æ”¶ä»¶ç®±"""
        try:
            ETL_DIR.mkdir(parents=True, exist_ok=True)
            
            inbox = []
            if INBOX_PATH.exists():
                with open(INBOX_PATH, "r", encoding="utf-8") as f:
                    inbox = json.load(f)
            
            final = result.get("final_result", {})
            prediction = final.get("ai_prediction", "æœªè¯Šæ–­")
            ground_truth = mission["expert_term"]
            
            # å¢å¼ºå¥å£®æ€§ï¼šç¡®ä¿æ˜¯å­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒ
            pred_val = str(prediction) if not isinstance(prediction, list) else ", ".join([str(x) for x in prediction])
            gt_val = str(ground_truth)
            
            record = {
                "id": f"batch_ins_{uuid.uuid4().hex[:8]}",
                "timestamp": datetime.now().isoformat(),
                "domain": "insurance",
                "query": result["messages"][0]["content"] if result["messages"] else "",
                "ai_prediction": prediction,
                "ground_truth": ground_truth,
                "category": mission["category"],
                "confidence": final.get("confidence", 0),
                "persona": mission.get("persona", "ä¼ä¸šç®¡ç†è€…"),
                "industry": mission.get("industry", "æœªçŸ¥"),
                "company_size": mission.get("company_size", "æœªçŸ¥"),
                "tone": mission.get("tone", "è¿·èŒ«"),
                "dialogue_path": result["messages"],
                "total_turns": final.get("total_turns", len(result["messages"])),
                "diagnosis_correct": pred_val in gt_val or gt_val in pred_val,
                "source": "batch_insurance_v1",
                "status": "pending"
            }
            
            inbox.append(record)
            
            with open(INBOX_PATH, "w", encoding="utf-8") as f:
                json.dump(inbox, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ‰¹é‡è®°å½•ä¿å­˜: {record['id']} | {mission.get('category_short', '')}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    
    def pause(self):
        """æš‚åœæ‰¹é‡ä»»åŠ¡"""
        self._paused = True
        return {"status": "paused"}
    
    def resume(self):
        """æ¢å¤æ‰¹é‡ä»»åŠ¡"""
        self._paused = False
        return {"status": "resumed"}
    
    def cancel(self):
        """å–æ¶ˆæ‰¹é‡ä»»åŠ¡"""
        self._cancelled = True
        return {"status": "cancelled"}
    
    def get_status(self) -> dict:
        """è·å–å½“å‰çŠ¶æ€ - è¿”å›å‰ç«¯æœŸæœ›çš„æ ¼å¼"""
        # ç¡®å®šçŠ¶æ€å­—ç¬¦ä¸²
        if self._cancelled:
            state = "cancelled"
        elif self._paused:
            state = "paused"
        elif self._running:
            state = "running"
        else:
            state = "idle"
        
        completed = self._progress.get("completed", 0)
        total = self._progress.get("total", 0)
        
        return {
            "state": state,
            "current_task": completed,
            "total_tasks": total,
            "progress": f"{completed}/{total}",
            "progress_percent": int((completed / total * 100)) if total > 0 else 0,
            "elapsed_seconds": 0,
            "success_count": completed,
            "error_count": 0,
            "recent_results": [],
            "recent_errors": [],
            # ä¿ç•™æ—§å­—æ®µå…¼å®¹
            "running": self._running,
            "paused": self._paused,
            "cancelled": self._cancelled
        }


# å‘½ä»¤è¡Œå…¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¿é™©å¯†å¿ƒæ‰¹é‡æŒ–æ˜")
    parser.add_argument("--count", type=int, default=10, help="ç”Ÿæˆæ•°é‡")
    args = parser.parse_args()
    
    runner = InsuranceBatchRunner()
    print(f"ğŸš€ å¯åŠ¨æ‰¹é‡ä¿é™©è¯Šæ–­æŒ–æ˜ï¼Œç›®æ ‡: {args.count} æ¡")
    runner._run_batch(args.count)
    print("âœ… æ‰¹é‡ä»»åŠ¡å®Œæˆ")
