"""
ğŸ­ ä¿é™©å¯†å¿ƒ - AI äº’åšä»¿çœŸå›¾ (Insurance Graph Engine)
=====================================================
æ ¸å¿ƒèŒèƒ½ï¼šç¼–æ’ä¿é™©é¡¾é—®ä¸ä¼ä¸šå®¢æˆ·çš„å¤šè½®å¯¹è¯ä»¿çœŸ
"""

import json
import os
from typing import TypedDict, List, Optional, Annotated
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, END
from dotenv import load_dotenv

from .prompts import expert_prompt, novice_prompt, opening_prompt
from .domain_manager import DomainManager

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class SimulationState(TypedDict):
    """ä»¿çœŸçŠ¶æ€å®šä¹‰"""
    messages: List[dict]
    mission: dict
    turn_count: int
    diagnosis_history: List[dict]
    final_result: Optional[dict]
    domain: str
    status: str


def create_insurance_simulation_graph(model_name: str = "glm-4"):
    """åˆ›å»ºä¿é™©é¢†åŸŸä»¿çœŸå›¾"""
    
    # åˆå§‹åŒ– LLM (æ™ºè°± API)
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_API_BASE", "https://open.bigmodel.cn/api/paas/v4/")
    
    llm = ChatOpenAI(
        model=model_name,
        temperature=0.7,
        max_tokens=2000,
        openai_api_key=api_key,
        openai_api_base=api_base
    )
    
    def initialize_simulation(state: SimulationState) -> SimulationState:
        """åˆå§‹åŒ–ä»¿çœŸ - ç”Ÿæˆä¼ä¸šå®¢æˆ·çš„ç§˜å¯†ä»»åŠ¡"""
        domain = state.get("domain", "insurance")
        dm = DomainManager(domain)
        mission = dm.generate_secret_mission()
        
        state["mission"] = mission
        state["messages"] = []
        state["turn_count"] = 0
        state["diagnosis_history"] = []
        state["status"] = "initialized"
        
        return state
    
    def generate_opening(state: SimulationState) -> SimulationState:
        """ç”Ÿæˆä¼ä¸šå®¢æˆ·çš„å¼€åœºç™½"""
        mission = state["mission"]
        
        prompt = opening_prompt.format(
            secret_user_intent=mission["novice_intent"],
            secret_category=mission["category"],
            persona_role=mission.get("persona", "ä¼ä¸šç®¡ç†è€…"),
            persona_tone=mission.get("tone", "è¿·èŒ«")
        )
        
        response = llm.invoke([HumanMessage(content=prompt)])
        opening = response.content.strip()
        
        # è®°å½•å¼€åœºç™½
        state["messages"].append({
            "role": "human",
            "content": f"æˆ‘æ˜¯{mission.get('persona', 'ä¼ä¸šç®¡ç†è€…')}ï¼Œ{opening}",
            "step": 1
        })
        state["turn_count"] = 1
        state["status"] = "active"
        
        return state
    
    def expert_response(state: SimulationState) -> SimulationState:
        """ä¿é™©é¡¾é—®å“åº” - è¯Šæ–­å¹¶è¿½é—®"""
        domain = state.get("domain", "insurance")
        dm = DomainManager(domain)
        taxonomy_context = dm.get_expert_context()
        
        # æ ¼å¼åŒ–å¯¹è¯å†å²
        messages_text = "\n".join([
            f"{'å®¢æˆ·' if m['role'] == 'human' else 'é¡¾é—®'}: {m['content']}"
            for m in state["messages"]
        ])
        
        prompt = expert_prompt.format(
            taxonomy_context=taxonomy_context,
            messages=messages_text
        )
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        try:
            # è§£æ JSON å“åº”
            content = response.content.strip()
            # å°è¯•æå– JSON
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            expert_data = json.loads(content)
        except json.JSONDecodeError:
            # è§£æå¤±è´¥æ—¶çš„å¤‡ç”¨å¤„ç†
            expert_data = {
                "diagnosis_reasoning": {"confidence": 0.5},
                "analysis_data": {"status": "active", "matched_service": "æœªçŸ¥"},
                "reply_to_user": response.content[:200]
            }
        
        # è®°å½•é¡¾é—®å“åº”
        state["messages"].append({
            "role": "ai",
            "content": expert_data.get("reply_to_user", "è¯·æ‚¨è¯¦ç»†è¯´è¯´æƒ…å†µ"),
            "step": state["turn_count"] + 1,
            "diagnosis": expert_data.get("diagnosis_reasoning", {})
        })
        
        # æ›´æ–°è¯Šæ–­å†å²
        state["diagnosis_history"].append({
            "turn": state["turn_count"] + 1,
            "data": expert_data.get("analysis_data", {})
        })
        
        # æ£€æŸ¥æ˜¯å¦ç»“æŸ
        status = expert_data.get("analysis_data", {}).get("status", "active")
        if status == "concluded" or state["turn_count"] >= 6:
            state["status"] = "concluded"
            state["final_result"] = {
                "predicted_service": expert_data.get("analysis_data", {}).get("matched_service", "æœªè¯Šæ–­"),
                "confidence": expert_data.get("diagnosis_reasoning", {}).get("confidence", 0),
                "ground_truth": state["mission"]["expert_term"],
                "total_turns": state["turn_count"] + 1
            }
        
        state["turn_count"] += 1
        return state
    
    def novice_response(state: SimulationState) -> SimulationState:
        """ä¼ä¸šå®¢æˆ·å“åº” - å›ç­”è¿½é—®"""
        if state["status"] == "concluded":
            return state
        
        mission = state["mission"]
        
        # æ ¼å¼åŒ–å¯¹è¯å†å²
        messages_text = "\n".join([
            f"{'å®¢æˆ·' if m['role'] == 'human' else 'é¡¾é—®'}: {m['content']}"
            for m in state["messages"]
        ])
        
        prompt = novice_prompt.format(
            secret_user_intent=mission["novice_intent"],
            secret_category=mission["category"],
            persona_role=mission.get("persona", "ä¼ä¸šç®¡ç†è€…"),
            persona_tone=mission.get("tone", "è¿·èŒ«"),
            messages=messages_text
        )
        
        response = llm.invoke([HumanMessage(content=prompt)])
        
        try:
            content = response.content.strip()
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            novice_data = json.loads(content)
        except json.JSONDecodeError:
            novice_data = {
                "response": "æ˜¯çš„ï¼Œå°±æ˜¯è¿™æ ·çš„æƒ…å†µ",
                "revealed_info": [],
                "hidden_info": []
            }
        
        # è®°å½•å®¢æˆ·å“åº”
        state["messages"].append({
            "role": "human",
            "content": novice_data.get("response", "æ˜¯çš„"),
            "step": state["turn_count"] + 1
        })
        
        state["turn_count"] += 1
        return state
    
    def should_continue(state: SimulationState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­ä»¿çœŸ"""
        if state["status"] == "concluded":
            return "end"
        if state["turn_count"] >= 8:
            return "end"
        return "continue"
    
    # æ„å»ºçŠ¶æ€å›¾
    workflow = StateGraph(SimulationState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("initialize", initialize_simulation)
    workflow.add_node("opening", generate_opening)
    workflow.add_node("expert", expert_response)
    workflow.add_node("novice", novice_response)
    
    # è®¾ç½®è¾¹
    workflow.set_entry_point("initialize")
    workflow.add_edge("initialize", "opening")
    workflow.add_edge("opening", "expert")
    workflow.add_conditional_edges(
        "expert",
        should_continue,
        {
            "continue": "novice",
            "end": END
        }
    )
    workflow.add_edge("novice", "expert")
    
    return workflow.compile()


# æµ‹è¯•å…¥å£
if __name__ == "__main__":
    graph = create_insurance_simulation_graph()
    
    initial_state = {
        "messages": [],
        "mission": {},
        "turn_count": 0,
        "diagnosis_history": [],
        "final_result": None,
        "domain": "insurance",
        "status": "pending"
    }
    
    result = graph.invoke(initial_state)
    print("\nğŸ“Š ä»¿çœŸç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))
